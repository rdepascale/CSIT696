{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdftotext\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from readability import Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## Process a directory of PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('test_pdf/MedvedevaEtAl2019.pdf'),\n",
       " PosixPath('test_pdf/KDD97-003.pdf'),\n",
       " PosixPath('test_pdf/P99-1001.pdf'),\n",
       " PosixPath('test_pdf/10.1007978-3-319-67056-018.pdf'),\n",
       " PosixPath('test_pdf/dummy_test.pdf')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust directory to point to location of files\n",
    "directory = 'test_pdf/'\n",
    "\n",
    "# create file list of pdf in directory\n",
    "pdf_folder = Path(directory).rglob('*.pdf')\n",
    "\n",
    "# create list of files and verify contents\n",
    "# should be 5 if using supplied 'test_pdf' directory\n",
    "files = [file for file in pdf_folder]\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through each file and\n",
    "* Tokenize file text\n",
    "* Create consistent case `.lower()` for each token\n",
    "* Remove tokens from `nltk` library `english` stopwords\n",
    "* Remove non-`.isalpha()` tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "multi_corpus = []\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "# iterate every file in directory\n",
    "for file in files:\n",
    "    # open file\n",
    "    with open(file, 'rb') as f:\n",
    "        # conversion with pdftotext\n",
    "        multi_pdf = pdftotext.PDF(f)\n",
    "        multi_corpus.append(''.join(multi_pdf))\n",
    "        # place current pdf text into list of tokens\n",
    "        tokens += nltk.word_tokenize(''.join(multi_pdf))\n",
    "        #corpus.append(tokens)\n",
    "\n",
    "# update tokens by setting all to lowercase,\n",
    "# removing stopwords,\n",
    "# removing non-alphanumeric\n",
    "tokens_removed = [word.lower() for word in tokens\n",
    "                  if word.lower() not in stopWords\n",
    "                  and word.isalpha()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## based on `top_n_words` to search for of `tokens_removed` (no stopwords) create a frequency distribution `fd` and place that number of words in list `target_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_words = 10\n",
    "fd = nltk.FreqDist(tokens_removed)\n",
    "target_words = sorted(fd, key = fd.get, reverse = True)[:top_n_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Clustering\n",
    "***\n",
    "## TF-IDF\n",
    "* take unique tokens from each pdf being fed as input\n",
    "* store each token as a string in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(multi_corpus)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "dfM = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set properties will allow us to remove every column that is not a targeted word from the early NLTK selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>case</th>\n",
       "      <th>cases</th>\n",
       "      <th>data</th>\n",
       "      <th>information</th>\n",
       "      <th>learning</th>\n",
       "      <th>mining</th>\n",
       "      <th>results</th>\n",
       "      <th>text</th>\n",
       "      <th>used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023118</td>\n",
       "      <td>0.082652</td>\n",
       "      <td>0.142561</td>\n",
       "      <td>0.047975</td>\n",
       "      <td>0.024673</td>\n",
       "      <td>0.036324</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>0.035639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.055444</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.045688</td>\n",
       "      <td>0.016801</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.018481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034813</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.098508</td>\n",
       "      <td>0.011259</td>\n",
       "      <td>0.157080</td>\n",
       "      <td>0.011259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.143512</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.092931</td>\n",
       "      <td>0.076869</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>0.184481</td>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.238740</td>\n",
       "      <td>0.033272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027596</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   articles      case     cases      data  information  learning    mining  \\\n",
       "0  0.023118  0.082652  0.142561  0.047975     0.024673  0.036324  0.002431   \n",
       "1  0.000000  0.007946  0.002361  0.055444     0.008401  0.001680  0.045688   \n",
       "2  0.034813  0.005325  0.000000  0.103584     0.103584  0.002252  0.098508   \n",
       "3  0.143512  0.005426  0.001612  0.092931     0.076869  0.061954  0.184481   \n",
       "4  0.000000  0.000000  0.000000  0.027596     0.003942  0.017740  0.000000   \n",
       "\n",
       "    results      text      used  \n",
       "0  0.029470  0.017827  0.035639  \n",
       "1  0.016801  0.019864  0.018481  \n",
       "2  0.011259  0.157080  0.011259  \n",
       "3  0.030977  0.238740  0.033272  \n",
       "4  0.051250  0.000000  0.023654  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_columns = list(set(feature_names).difference(target_words))\n",
    "dfM.drop(columns = dropped_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create dictionary of k:v pair index : pdf filename to rename pandas rows for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MedvedevaEtAl2019.pdf\n",
      "1 KDD97-003.pdf\n",
      "2 P99-1001.pdf\n",
      "3 10.1007978-3-319-67056-018.pdf\n",
      "4 dummy_test.pdf\n"
     ]
    }
   ],
   "source": [
    "names = {}\n",
    "for x in range(len(files)):\n",
    "    print(str(x)+' '+str(files[x])[9:])\n",
    "    names[x] = str(files[x])[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfM.rename(index=names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articles</th>\n",
       "      <th>case</th>\n",
       "      <th>cases</th>\n",
       "      <th>data</th>\n",
       "      <th>information</th>\n",
       "      <th>learning</th>\n",
       "      <th>mining</th>\n",
       "      <th>results</th>\n",
       "      <th>text</th>\n",
       "      <th>used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedvedevaEtAl2019.pdf</th>\n",
       "      <td>0.023118</td>\n",
       "      <td>0.082652</td>\n",
       "      <td>0.142561</td>\n",
       "      <td>0.047975</td>\n",
       "      <td>0.024673</td>\n",
       "      <td>0.036324</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.017827</td>\n",
       "      <td>0.035639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDD97-003.pdf</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.055444</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.045688</td>\n",
       "      <td>0.016801</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.018481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P99-1001.pdf</th>\n",
       "      <td>0.034813</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>0.002252</td>\n",
       "      <td>0.098508</td>\n",
       "      <td>0.011259</td>\n",
       "      <td>0.157080</td>\n",
       "      <td>0.011259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1007978-3-319-67056-018.pdf</th>\n",
       "      <td>0.143512</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.092931</td>\n",
       "      <td>0.076869</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>0.184481</td>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.238740</td>\n",
       "      <td>0.033272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy_test.pdf</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027596</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                articles      case     cases      data  \\\n",
       "MedvedevaEtAl2019.pdf           0.023118  0.082652  0.142561  0.047975   \n",
       "KDD97-003.pdf                   0.000000  0.007946  0.002361  0.055444   \n",
       "P99-1001.pdf                    0.034813  0.005325  0.000000  0.103584   \n",
       "10.1007978-3-319-67056-018.pdf  0.143512  0.005426  0.001612  0.092931   \n",
       "dummy_test.pdf                  0.000000  0.000000  0.000000  0.027596   \n",
       "\n",
       "                                information  learning    mining   results  \\\n",
       "MedvedevaEtAl2019.pdf              0.024673  0.036324  0.002431  0.029470   \n",
       "KDD97-003.pdf                      0.008401  0.001680  0.045688  0.016801   \n",
       "P99-1001.pdf                       0.103584  0.002252  0.098508  0.011259   \n",
       "10.1007978-3-319-67056-018.pdf     0.076869  0.061954  0.184481  0.030977   \n",
       "dummy_test.pdf                     0.003942  0.017740  0.000000  0.051250   \n",
       "\n",
       "                                    text      used  \n",
       "MedvedevaEtAl2019.pdf           0.017827  0.035639  \n",
       "KDD97-003.pdf                   0.019864  0.018481  \n",
       "P99-1001.pdf                    0.157080  0.011259  \n",
       "10.1007978-3-319-67056-018.pdf  0.238740  0.033272  \n",
       "dummy_test.pdf                  0.000000  0.023654  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfM.drop(columns = dropped_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSummary = pd.DataFrame({'word': [], 'max TF-IDF value' : [], 'file' : []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in target_words:\n",
    "    dfSummary = dfSummary.append({'word': word, 'max TF-IDF value' : dfM[word].max(), 'file' : dfM[word].idxmax()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>max TF-IDF value</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>0.238740</td>\n",
       "      <td>10.1007978-3-319-67056-018.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mining</td>\n",
       "      <td>0.184481</td>\n",
       "      <td>10.1007978-3-319-67056-018.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>articles</td>\n",
       "      <td>0.143512</td>\n",
       "      <td>10.1007978-3-319-67056-018.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cases</td>\n",
       "      <td>0.142561</td>\n",
       "      <td>MedvedevaEtAl2019.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>P99-1001.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>information</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>P99-1001.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>case</td>\n",
       "      <td>0.082652</td>\n",
       "      <td>MedvedevaEtAl2019.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>10.1007978-3-319-67056-018.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>results</td>\n",
       "      <td>0.051250</td>\n",
       "      <td>dummy_test.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>used</td>\n",
       "      <td>0.035639</td>\n",
       "      <td>MedvedevaEtAl2019.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  max TF-IDF value                            file\n",
       "0         text          0.238740  10.1007978-3-319-67056-018.pdf\n",
       "2       mining          0.184481  10.1007978-3-319-67056-018.pdf\n",
       "5     articles          0.143512  10.1007978-3-319-67056-018.pdf\n",
       "4        cases          0.142561           MedvedevaEtAl2019.pdf\n",
       "1         data          0.103584                    P99-1001.pdf\n",
       "3  information          0.103584                    P99-1001.pdf\n",
       "8         case          0.082652           MedvedevaEtAl2019.pdf\n",
       "6     learning          0.061954  10.1007978-3-319-67056-018.pdf\n",
       "7      results          0.051250                  dummy_test.pdf\n",
       "9         used          0.035639           MedvedevaEtAl2019.pdf"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSummary.sort_values(by = 'max TF-IDF value', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans\n",
    "* Predict the cluster for `search_text`\n",
    "* access `dfM` dataframe utilizing prediction to determine pdf file where target text is likely to be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00413669 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00194255 0.         ... 0.00722322 0.00240774 0.00722322]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.0028766  ... 0.         0.         0.        ]\n",
      " [0.         0.01143798 0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "num = len(multi_pdf) # set clusters to number of documents being scrubbed?\n",
    "kmeans = KMeans(n_clusters = num, init = 'k-means++', max_iter = 500, n_init = 1)\n",
    "kmeans.fit(vectors)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids) #This will print cluster centroids as tf-idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1007978-3-319-67056-018.pdf'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_text = \"how to run on the water\"\n",
    "predicted = kmeans.predict(vectorizer.transform([search_text]))\n",
    "dfM.loc[ names[ predicted[0] ] ].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "* Find Flesch-Kincaid Grade Level.\n",
    "* Find TF-IDF average of scored document from `top_n_words` `nltk` Frequency Distribution of corpus.\n",
    "* Find TF-IDF average of scored document from `top_n_words` `nltk` Frequency Distribution of scored document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('test_pdf/MedvedevaEtAl2019.pdf'),\n",
       " PosixPath('test_pdf/KDD97-003.pdf'),\n",
       " PosixPath('test_pdf/P99-1001.pdf'),\n",
       " PosixPath('test_pdf/10.1007978-3-319-67056-018.pdf'),\n",
       " PosixPath('test_pdf/dummy_test.pdf')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all files from original scan\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_pdf/MedvedevaEtAl2019.pdf'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# string conversion and indexing produces path\n",
    "str(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to string conversion of desired file\n",
    "path = str(files[0])\n",
    "with open(path, \"rb\") as f:\n",
    "    pdf = pdftotext.PDF(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize text string, iterate through pdf, append text\n",
    "text = ''\n",
    "for page in pdf:\n",
    "    text+=page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.704919385560462, '13')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score text via Flesch-Kincaid Grade Level metric\n",
    "r = Readability(text)\n",
    "fk = r.flesch_kincaid()\n",
    "fk.score, fk.grade_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0442669256448735"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean score of top_n_words in corpus for doc in files index 0\n",
    "corpus_score = dfM.drop(columns = dropped_columns).iloc[0].mean()\n",
    "corpus_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize file from index 0 document and remove stopwords\n",
    "target_tokens = nltk.word_tokenize(''.join(multi_corpus[0]))\n",
    "target_tokens_removed = [word.lower() for word in target_tokens\n",
    "                         if word.lower() not in stopWords and word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilize previously defined top_n_words to find FreqDist for current document with tokens removed\n",
    "fdDoc = nltk.FreqDist(target_tokens_removed)\n",
    "target_doc_words = sorted(fdDoc, key = fdDoc.get, reverse = True)[:top_n_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cases',\n",
       " 'case',\n",
       " 'violation',\n",
       " 'court',\n",
       " 'law',\n",
       " 'article',\n",
       " 'data',\n",
       " 'decisions',\n",
       " 'legal',\n",
       " 'using']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_doc_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>case</th>\n",
       "      <th>cases</th>\n",
       "      <th>court</th>\n",
       "      <th>data</th>\n",
       "      <th>decisions</th>\n",
       "      <th>law</th>\n",
       "      <th>legal</th>\n",
       "      <th>using</th>\n",
       "      <th>violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedvedevaEtAl2019.pdf</th>\n",
       "      <td>0.087031</td>\n",
       "      <td>0.082652</td>\n",
       "      <td>0.142561</td>\n",
       "      <td>0.117941</td>\n",
       "      <td>0.047975</td>\n",
       "      <td>0.08486</td>\n",
       "      <td>0.107873</td>\n",
       "      <td>0.056832</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDD97-003.pdf</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055444</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P99-1001.pdf</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013511</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1007978-3-319-67056-018.pdf</th>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.005426</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092931</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.036714</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy_test.pdf</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027596</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 article      case     cases     court  \\\n",
       "MedvedevaEtAl2019.pdf           0.087031  0.082652  0.142561  0.117941   \n",
       "KDD97-003.pdf                   0.000000  0.007946  0.002361  0.000000   \n",
       "P99-1001.pdf                    0.000000  0.005325  0.000000  0.000000   \n",
       "10.1007978-3-319-67056-018.pdf  0.003885  0.005426  0.001612  0.000000   \n",
       "dummy_test.pdf                  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                                    data  decisions       law     legal  \\\n",
       "MedvedevaEtAl2019.pdf           0.047975    0.08486  0.107873  0.056832   \n",
       "KDD97-003.pdf                   0.055444    0.00000  0.000000  0.000000   \n",
       "P99-1001.pdf                    0.103584    0.00000  0.000000  0.000000   \n",
       "10.1007978-3-319-67056-018.pdf  0.092931    0.00000  0.000000  0.001612   \n",
       "dummy_test.pdf                  0.027596    0.00000  0.000000  0.002770   \n",
       "\n",
       "                                   using  violation  \n",
       "MedvedevaEtAl2019.pdf           0.039065     0.2028  \n",
       "KDD97-003.pdf                   0.003360     0.0000  \n",
       "P99-1001.pdf                    0.013511     0.0000  \n",
       "10.1007978-3-319-67056-018.pdf  0.036714     0.0000  \n",
       "dummy_test.pdf                  0.009856     0.0000  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfM.drop(columns = list(set(feature_names).difference(target_doc_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09695889184932609"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean score of top_n_words in doc in files index 0 to corpus\n",
    "doc_score = dfM.drop(columns = list(set(feature_names).difference(target_doc_words))).iloc[0].mean()\n",
    "doc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.704919385560462, 0.0442669256448735, 0.09695889184932609)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fk.score, corpus_score, doc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of Flesch-Kincaid Grade Level scores\n",
    "fk_score = []\n",
    "# initialize list of TF-IDF scores for file among corpus top_n_words\n",
    "corpus_score = []\n",
    "# initialize list of TF-IDF scores for file top_n_words among corpus\n",
    "doc_score = []\n",
    "\n",
    "# iterate every file in directory\n",
    "for file_index in range(len(files)):\n",
    "    # append Flesch-Kincaid Grade Level Score\n",
    "    fk_score.append( Readability(multi_corpus[file_index]).flesch_kincaid().score )\n",
    "    # tokenize file from file_index document and remove stopWords\n",
    "    target_tokens = [word.lower() for word in nltk.word_tokenize(''.join(multi_corpus[file_index])) if word.lower() not in stopWords and word.isalpha()]\n",
    "    # append corpus score\n",
    "    corpus_score.append(dfM.drop(columns = dropped_columns).iloc[file_index].mean())\n",
    "    # append doc score\n",
    "    fdDoc = nltk.FreqDist(target_tokens)\n",
    "    target_doc_words = sorted(fdDoc, key = fdDoc.get, reverse = True)[:top_n_words]\n",
    "    doc_score.append(dfM.drop(columns = list(set(feature_names).difference(target_doc_words))).iloc[file_index].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.704919385560462 0.0442669256448735 0.09695889184932609\n",
      "11.699757630092137 0.01766658069771749 0.09954108374763701\n",
      "10.309591337877851 0.05276634587570308 0.08872207670385866\n",
      "10.649642785973345 0.08697753413614841 0.10947173304751992\n",
      "10.6788966015096 0.012418278795192379 0.15977827983685147\n"
     ]
    }
   ],
   "source": [
    "for file_index in range(len(files)):\n",
    "    print(fk_score[file_index], corpus_score[file_index], doc_score[file_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfScore = pd.DataFrame(list(zip(fk_score, corpus_score, doc_score)), columns = ['Flesch-Kincaid', 'Corpus TF-IDF', 'Doc TF-IDF'])\n",
    "dfScore.rename(index=names, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flesch-Kincaid</th>\n",
       "      <th>Corpus TF-IDF</th>\n",
       "      <th>Doc TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MedvedevaEtAl2019.pdf</th>\n",
       "      <td>12.704919</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>0.096959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KDD97-003.pdf</th>\n",
       "      <td>11.699758</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.099541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P99-1001.pdf</th>\n",
       "      <td>10.309591</td>\n",
       "      <td>0.052766</td>\n",
       "      <td>0.088722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.1007978-3-319-67056-018.pdf</th>\n",
       "      <td>10.649643</td>\n",
       "      <td>0.086978</td>\n",
       "      <td>0.109472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy_test.pdf</th>\n",
       "      <td>10.678897</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.159778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Flesch-Kincaid  Corpus TF-IDF  Doc TF-IDF\n",
       "MedvedevaEtAl2019.pdf                12.704919       0.044267    0.096959\n",
       "KDD97-003.pdf                        11.699758       0.017667    0.099541\n",
       "P99-1001.pdf                         10.309591       0.052766    0.088722\n",
       "10.1007978-3-319-67056-018.pdf       10.649643       0.086978    0.109472\n",
       "dummy_test.pdf                       10.678897       0.012418    0.159778"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO\n",
    "* Look at 3 scores for papers with **Teacher** grade attached.\n",
    "* Look for equation to fit 3 scores to **Teacher** score.\n",
    "* Scoring assumptions\n",
    "  * student should be able to write at grade level\n",
    "  * vocab choice of all students (TF-IDF of corpus) and individual (TF-IDF of doc) are important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
